{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>adm0_id</th>\n",
       "      <th>adm0_name</th>\n",
       "      <th>adm1_id</th>\n",
       "      <th>adm1_name</th>\n",
       "      <th>mkt_id</th>\n",
       "      <th>mkt_name</th>\n",
       "      <th>cm_id</th>\n",
       "      <th>cm_name</th>\n",
       "      <th>cur_id</th>\n",
       "      <th>cur_name</th>\n",
       "      <th>pt_id</th>\n",
       "      <th>pt_name</th>\n",
       "      <th>um_id</th>\n",
       "      <th>um_name</th>\n",
       "      <th>mp_price</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>month_year</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1-2007</th>\n",
       "      <td>116.0</td>\n",
       "      <td>Indonesia</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>974</td>\n",
       "      <td>National Average</td>\n",
       "      <td>52</td>\n",
       "      <td>Rice - Retail</td>\n",
       "      <td>0.0</td>\n",
       "      <td>IDR</td>\n",
       "      <td>15</td>\n",
       "      <td>Retail</td>\n",
       "      <td>5</td>\n",
       "      <td>KG</td>\n",
       "      <td>5941.9752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2-2007</th>\n",
       "      <td>116.0</td>\n",
       "      <td>Indonesia</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>974</td>\n",
       "      <td>National Average</td>\n",
       "      <td>52</td>\n",
       "      <td>Rice - Retail</td>\n",
       "      <td>0.0</td>\n",
       "      <td>IDR</td>\n",
       "      <td>15</td>\n",
       "      <td>Retail</td>\n",
       "      <td>5</td>\n",
       "      <td>KG</td>\n",
       "      <td>6445.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3-2007</th>\n",
       "      <td>116.0</td>\n",
       "      <td>Indonesia</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>974</td>\n",
       "      <td>National Average</td>\n",
       "      <td>52</td>\n",
       "      <td>Rice - Retail</td>\n",
       "      <td>0.0</td>\n",
       "      <td>IDR</td>\n",
       "      <td>15</td>\n",
       "      <td>Retail</td>\n",
       "      <td>5</td>\n",
       "      <td>KG</td>\n",
       "      <td>6414.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4-2007</th>\n",
       "      <td>116.0</td>\n",
       "      <td>Indonesia</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>974</td>\n",
       "      <td>National Average</td>\n",
       "      <td>52</td>\n",
       "      <td>Rice - Retail</td>\n",
       "      <td>0.0</td>\n",
       "      <td>IDR</td>\n",
       "      <td>15</td>\n",
       "      <td>Retail</td>\n",
       "      <td>5</td>\n",
       "      <td>KG</td>\n",
       "      <td>6083.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5-2007</th>\n",
       "      <td>116.0</td>\n",
       "      <td>Indonesia</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>974</td>\n",
       "      <td>National Average</td>\n",
       "      <td>52</td>\n",
       "      <td>Rice - Retail</td>\n",
       "      <td>0.0</td>\n",
       "      <td>IDR</td>\n",
       "      <td>15</td>\n",
       "      <td>Retail</td>\n",
       "      <td>5</td>\n",
       "      <td>KG</td>\n",
       "      <td>5955.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8-2019</th>\n",
       "      <td>116.0</td>\n",
       "      <td>Indonesia</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>974</td>\n",
       "      <td>National Average</td>\n",
       "      <td>604</td>\n",
       "      <td>Chili (birdâ€™s eye)   - Retail</td>\n",
       "      <td>0.0</td>\n",
       "      <td>IDR</td>\n",
       "      <td>15</td>\n",
       "      <td>Retail</td>\n",
       "      <td>5</td>\n",
       "      <td>KG</td>\n",
       "      <td>79087.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9-2019</th>\n",
       "      <td>116.0</td>\n",
       "      <td>Indonesia</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>974</td>\n",
       "      <td>National Average</td>\n",
       "      <td>604</td>\n",
       "      <td>Chili (birdâ€™s eye)   - Retail</td>\n",
       "      <td>0.0</td>\n",
       "      <td>IDR</td>\n",
       "      <td>15</td>\n",
       "      <td>Retail</td>\n",
       "      <td>5</td>\n",
       "      <td>KG</td>\n",
       "      <td>68481.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10-2019</th>\n",
       "      <td>116.0</td>\n",
       "      <td>Indonesia</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>974</td>\n",
       "      <td>National Average</td>\n",
       "      <td>604</td>\n",
       "      <td>Chili (birdâ€™s eye)   - Retail</td>\n",
       "      <td>0.0</td>\n",
       "      <td>IDR</td>\n",
       "      <td>15</td>\n",
       "      <td>Retail</td>\n",
       "      <td>5</td>\n",
       "      <td>KG</td>\n",
       "      <td>62181.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11-2019</th>\n",
       "      <td>116.0</td>\n",
       "      <td>Indonesia</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>974</td>\n",
       "      <td>National Average</td>\n",
       "      <td>604</td>\n",
       "      <td>Chili (birdâ€™s eye)   - Retail</td>\n",
       "      <td>0.0</td>\n",
       "      <td>IDR</td>\n",
       "      <td>15</td>\n",
       "      <td>Retail</td>\n",
       "      <td>5</td>\n",
       "      <td>KG</td>\n",
       "      <td>57536.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12-2019</th>\n",
       "      <td>116.0</td>\n",
       "      <td>Indonesia</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>974</td>\n",
       "      <td>National Average</td>\n",
       "      <td>604</td>\n",
       "      <td>Chili (birdâ€™s eye)   - Retail</td>\n",
       "      <td>0.0</td>\n",
       "      <td>IDR</td>\n",
       "      <td>15</td>\n",
       "      <td>Retail</td>\n",
       "      <td>5</td>\n",
       "      <td>KG</td>\n",
       "      <td>51892.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1633 rows Ã— 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            adm0_id  adm0_name  adm1_id  adm1_name  mkt_id          mkt_name  \\\n",
       "month_year                                                                     \n",
       "1-2007        116.0  Indonesia        0        NaN     974  National Average   \n",
       "2-2007        116.0  Indonesia        0        NaN     974  National Average   \n",
       "3-2007        116.0  Indonesia        0        NaN     974  National Average   \n",
       "4-2007        116.0  Indonesia        0        NaN     974  National Average   \n",
       "5-2007        116.0  Indonesia        0        NaN     974  National Average   \n",
       "...             ...        ...      ...        ...     ...               ...   \n",
       "8-2019        116.0  Indonesia        0        NaN     974  National Average   \n",
       "9-2019        116.0  Indonesia        0        NaN     974  National Average   \n",
       "10-2019       116.0  Indonesia        0        NaN     974  National Average   \n",
       "11-2019       116.0  Indonesia        0        NaN     974  National Average   \n",
       "12-2019       116.0  Indonesia        0        NaN     974  National Average   \n",
       "\n",
       "            cm_id                        cm_name  cur_id cur_name  pt_id  \\\n",
       "month_year                                                                 \n",
       "1-2007         52                  Rice - Retail     0.0      IDR     15   \n",
       "2-2007         52                  Rice - Retail     0.0      IDR     15   \n",
       "3-2007         52                  Rice - Retail     0.0      IDR     15   \n",
       "4-2007         52                  Rice - Retail     0.0      IDR     15   \n",
       "5-2007         52                  Rice - Retail     0.0      IDR     15   \n",
       "...           ...                            ...     ...      ...    ...   \n",
       "8-2019        604  Chili (birdâ€™s eye)   - Retail     0.0      IDR     15   \n",
       "9-2019        604  Chili (birdâ€™s eye)   - Retail     0.0      IDR     15   \n",
       "10-2019       604  Chili (birdâ€™s eye)   - Retail     0.0      IDR     15   \n",
       "11-2019       604  Chili (birdâ€™s eye)   - Retail     0.0      IDR     15   \n",
       "12-2019       604  Chili (birdâ€™s eye)   - Retail     0.0      IDR     15   \n",
       "\n",
       "           pt_name  um_id um_name    mp_price  \n",
       "month_year                                     \n",
       "1-2007      Retail      5      KG   5941.9752  \n",
       "2-2007      Retail      5      KG   6445.0000  \n",
       "3-2007      Retail      5      KG   6414.0000  \n",
       "4-2007      Retail      5      KG   6083.0000  \n",
       "5-2007      Retail      5      KG   5955.0000  \n",
       "...            ...    ...     ...         ...  \n",
       "8-2019      Retail      5      KG  79087.0000  \n",
       "9-2019      Retail      5      KG  68481.0000  \n",
       "10-2019     Retail      5      KG  62181.0000  \n",
       "11-2019     Retail      5      KG  57536.0000  \n",
       "12-2019     Retail      5      KG  51892.0000  \n",
       "\n",
       "[1633 rows x 15 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"foodprices_indonesia.csv\", index_col=\"month_year\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_unused_row_column(df, com_name, is_univariate=True):\n",
    "    df = df[df[\"cm_name\"].str.contains(com_name)]\n",
    "    df = df.drop(columns=[\"adm0_id\", \"adm0_name\", \"adm1_id\", \"adm1_name\",\n",
    "                          \"mkt_id\", \"mkt_name\", \"cm_id\", \"cur_id\", \"cur_name\", \n",
    "                          \"pt_id\", \"pt_name\", \"um_id\", \"um_name\"], axis=1)\n",
    "    if is_univariate:\n",
    "        df = df.drop(\"cm_name\", axis=1)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(data, train_all_bound, history_size, train_val_bound=None):\n",
    "    data_train = []\n",
    "    labels_train = []\n",
    "    data_test = []\n",
    "    labels_test = []\n",
    "    start_train = history_size\n",
    "    if train_val_bound is not None:\n",
    "        data_val = []\n",
    "        labels_val = []\n",
    "        end_train = train_val_bound\n",
    "        start_val = train_val_bound\n",
    "        end_val = train_all_bound\n",
    "    else:\n",
    "        end_train = train_all_bound\n",
    "    start_test = train_all_bound\n",
    "    end_test = len(data)\n",
    "    \n",
    "    for i in range(start_train, end_train):\n",
    "        indices = range(i-history_size, i)\n",
    "        # Reshape data from (history_size,) to (history_size, 1)\n",
    "        data_train.append(np.reshape(data[indices], (history_size, 1)))\n",
    "        labels_train.append(data[i])\n",
    "    \n",
    "    if train_val_bound is not None:\n",
    "        for i in range(start_val, end_val):\n",
    "            indices = range(i-history_size, i)\n",
    "            # Reshape data from (history_size,) to (history_size, 1)\n",
    "            data_val.append(np.reshape(data[indices], (history_size, 1)))\n",
    "            labels_val.append(data[i])\n",
    "        \n",
    "    for i in range(start_test, end_test):\n",
    "        indices = range(i-history_size, i)\n",
    "        # Reshape data from (history_size,) to (history_size, 1)\n",
    "        data_test.append(np.reshape(data[indices], (history_size, 1)))\n",
    "        labels_test.append(data[i])\n",
    "    \n",
    "    if train_val_bound is not None:\n",
    "        return (np.array(data_train), np.array(labels_train), \n",
    "    np.array(data_val), np.array(labels_val), \n",
    "    np.array(data_test), np.array(labels_test))\n",
    "    else:\n",
    "        return np.array(data_train), np.array(labels_train), np.array(data_test), np.array(labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(unit, input_shape, kernel_regularizer=None):\n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.LSTM(unit, input_shape=input_shape, kernel_regularizer=kernel_regularizer),\n",
    "        tf.keras.layers.Dense(1)\n",
    "    ])\n",
    "    \n",
    "    model.summary()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_model_result(history):\n",
    "    plt.figure(figsize=(10,10))\n",
    "    \n",
    "    # summarize history for loss\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'val'], loc='upper left')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the forecasting model with Chili (Red) data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "select only the \"Chili (red)\" data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "155"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_chili = drop_unused_row_column(df, \"Chili (red) - Retail\")\n",
    "data = df_chili[\"mp_price\"].values / 1000\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "define hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hyperparameters\n",
    "TRAIN_TEST_SPLIT = math.ceil(len(data) * 0.9)\n",
    "VAL_SPLIT = math.ceil(TRAIN_TEST_SPLIT * 0.9)\n",
    "HISTORY_SIZE = 10\n",
    "BUFFER_SIZE = 1000\n",
    "BATCH_SIZE = 5\n",
    "\n",
    "UNIT_SIZE = 11\n",
    "EPOCHS = 250"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "split the data into train, validation, and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train, x_val, y_val, x_test, y_test = split_data(data, TRAIN_TEST_SPLIT, HISTORY_SIZE, VAL_SPLIT)\n",
    "len(x_train), len(x_val), len(x_test)\n",
    "\n",
    "train = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "train = train.cache().shuffle(BUFFER_SIZE).batch(BATCH_SIZE).repeat()\n",
    "\n",
    "val = tf.data.Dataset.from_tensor_slices((x_val, y_val))\n",
    "val = val.batch(BATCH_SIZE).repeat()\n",
    "\n",
    "test = tf.data.Dataset.from_tensor_slices((x_test, y_test))\n",
    "test = test.batch(BATCH_SIZE).repeat()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "build a forecasting model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_11 (LSTM)               (None, 11)                572       \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1)                 12        \n",
      "=================================================================\n",
      "Total params: 584\n",
      "Trainable params: 584\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "chili_model = create_model(UNIT_SIZE, x_train.shape[-2:])\n",
    "#chili_model.load_weights(\"chili.h5\")\n",
    "chili_model.compile(optimizer='adam', loss='mse')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train with defined hyperparamters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n",
      "116/116 [==============================] - 5s 44ms/step - loss: 845.4029 - val_loss: 1519.3919\n",
      "Epoch 2/250\n",
      "116/116 [==============================] - 2s 18ms/step - loss: 731.5039 - val_loss: 1375.9823\n",
      "Epoch 3/250\n",
      "116/116 [==============================] - 2s 18ms/step - loss: 652.3071 - val_loss: 1215.4232\n",
      "Epoch 4/250\n",
      "116/116 [==============================] - 2s 18ms/step - loss: 542.8990 - val_loss: 1136.5858\n",
      "Epoch 5/250\n",
      "116/116 [==============================] - 3s 23ms/step - loss: 550.0238 - val_loss: 1066.9195\n",
      "Epoch 6/250\n",
      "116/116 [==============================] - 2s 19ms/step - loss: 475.1900 - val_loss: 1005.3975\n",
      "Epoch 7/250\n",
      "116/116 [==============================] - 2s 20ms/step - loss: 466.7049 - val_loss: 946.7420\n",
      "Epoch 8/250\n",
      "116/116 [==============================] - 2s 21ms/step - loss: 404.0960 - val_loss: 893.1683\n",
      "Epoch 9/250\n",
      "116/116 [==============================] - 2s 18ms/step - loss: 391.3861 - val_loss: 842.5101\n",
      "Epoch 10/250\n",
      "116/116 [==============================] - 2s 18ms/step - loss: 351.8421 - val_loss: 795.4222\n",
      "Epoch 11/250\n",
      "116/116 [==============================] - 2s 19ms/step - loss: 321.2317 - val_loss: 751.6085\n",
      "Epoch 12/250\n",
      "116/116 [==============================] - 2s 19ms/step - loss: 301.2816 - val_loss: 709.0007\n",
      "Epoch 13/250\n",
      "116/116 [==============================] - 2s 18ms/step - loss: 279.9423 - val_loss: 669.6824\n",
      "Epoch 14/250\n",
      "116/116 [==============================] - 2s 18ms/step - loss: 257.1075 - val_loss: 632.8934\n",
      "Epoch 15/250\n",
      "116/116 [==============================] - 2s 19ms/step - loss: 251.4101 - val_loss: 597.3085\n",
      "Epoch 16/250\n",
      "116/116 [==============================] - 2s 20ms/step - loss: 221.7916 - val_loss: 564.4774\n",
      "Epoch 17/250\n",
      "116/116 [==============================] - 2s 20ms/step - loss: 212.8609 - val_loss: 533.6550\n",
      "Epoch 18/250\n",
      "116/116 [==============================] - 2s 18ms/step - loss: 196.5929 - val_loss: 504.3395\n",
      "Epoch 19/250\n",
      "116/116 [==============================] - 2s 19ms/step - loss: 184.6096 - val_loss: 476.8123\n",
      "Epoch 20/250\n",
      "116/116 [==============================] - 2s 18ms/step - loss: 176.2606 - val_loss: 450.6454\n",
      "Epoch 21/250\n",
      "116/116 [==============================] - 2s 18ms/step - loss: 154.3743 - val_loss: 427.0130\n",
      "Epoch 22/250\n",
      "116/116 [==============================] - 2s 18ms/step - loss: 154.3002 - val_loss: 404.8483\n",
      "Epoch 23/250\n",
      "116/116 [==============================] - 2s 18ms/step - loss: 150.0389 - val_loss: 382.3910\n",
      "Epoch 24/250\n",
      "116/116 [==============================] - 2s 18ms/step - loss: 139.8000 - val_loss: 361.2902\n",
      "Epoch 25/250\n",
      "116/116 [==============================] - 2s 19ms/step - loss: 125.3769 - val_loss: 341.4696\n",
      "Epoch 26/250\n",
      "116/116 [==============================] - 2s 19ms/step - loss: 145.9422 - val_loss: 321.3448\n",
      "Epoch 27/250\n",
      "116/116 [==============================] - 2s 18ms/step - loss: 108.4140 - val_loss: 304.2125\n",
      "Epoch 28/250\n",
      "116/116 [==============================] - 2s 20ms/step - loss: 107.3428 - val_loss: 287.8299\n",
      "Epoch 29/250\n",
      "116/116 [==============================] - 2s 18ms/step - loss: 100.5420 - val_loss: 272.1134\n",
      "Epoch 30/250\n",
      "116/116 [==============================] - 2s 19ms/step - loss: 99.1033 - val_loss: 257.5130\n",
      "Epoch 31/250\n",
      "116/116 [==============================] - 2s 19ms/step - loss: 90.5280 - val_loss: 243.2574\n",
      "Epoch 32/250\n",
      "116/116 [==============================] - 2s 18ms/step - loss: 88.0546 - val_loss: 229.8370\n",
      "Epoch 33/250\n",
      "116/116 [==============================] - 2s 21ms/step - loss: 80.7455 - val_loss: 217.2476\n",
      "Epoch 34/250\n",
      "116/116 [==============================] - 2s 21ms/step - loss: 76.9937 - val_loss: 205.5006\n",
      "Epoch 35/250\n",
      "116/116 [==============================] - 2s 18ms/step - loss: 81.3035 - val_loss: 193.5174\n",
      "Epoch 36/250\n",
      "116/116 [==============================] - 2s 21ms/step - loss: 70.0844 - val_loss: 182.7256\n",
      "Epoch 37/250\n",
      "116/116 [==============================] - 2s 20ms/step - loss: 69.4872 - val_loss: 172.6908\n",
      "Epoch 38/250\n",
      "116/116 [==============================] - 2s 18ms/step - loss: 64.9381 - val_loss: 162.6078\n",
      "Epoch 39/250\n",
      "116/116 [==============================] - 2s 18ms/step - loss: 64.2180 - val_loss: 153.8209\n",
      "Epoch 40/250\n",
      "116/116 [==============================] - 2s 18ms/step - loss: 61.1395 - val_loss: 144.9178\n",
      "Epoch 41/250\n",
      "116/116 [==============================] - 2s 18ms/step - loss: 59.7961 - val_loss: 135.9275\n",
      "Epoch 42/250\n",
      "116/116 [==============================] - 2s 18ms/step - loss: 57.6605 - val_loss: 128.1237\n",
      "Epoch 43/250\n",
      "116/116 [==============================] - 2s 18ms/step - loss: 52.8158 - val_loss: 121.1034\n",
      "Epoch 44/250\n",
      "116/116 [==============================] - 2s 18ms/step - loss: 54.2206 - val_loss: 113.5723\n",
      "Epoch 45/250\n",
      "116/116 [==============================] - 2s 18ms/step - loss: 50.5951 - val_loss: 108.1402\n",
      "Epoch 46/250\n",
      "116/116 [==============================] - 2s 18ms/step - loss: 49.5088 - val_loss: 101.5903\n",
      "Epoch 47/250\n",
      "116/116 [==============================] - 2s 18ms/step - loss: 45.2588 - val_loss: 96.1483\n",
      "Epoch 48/250\n",
      "116/116 [==============================] - 2s 18ms/step - loss: 47.8310 - val_loss: 90.6910\n",
      "Epoch 49/250\n",
      "116/116 [==============================] - 2s 18ms/step - loss: 43.6601 - val_loss: 85.7748\n",
      "Epoch 50/250\n",
      "116/116 [==============================] - 2s 18ms/step - loss: 44.3483 - val_loss: 81.7071\n",
      "Epoch 51/250\n",
      "116/116 [==============================] - 2s 20ms/step - loss: 42.2305 - val_loss: 76.6568\n",
      "Epoch 52/250\n",
      "116/116 [==============================] - 2s 19ms/step - loss: 41.4751 - val_loss: 72.2307\n",
      "Epoch 53/250\n",
      "116/116 [==============================] - 2s 18ms/step - loss: 46.1076 - val_loss: 68.1769\n",
      "Epoch 54/250\n",
      "116/116 [==============================] - 2s 18ms/step - loss: 39.1186 - val_loss: 64.5277\n",
      "Epoch 55/250\n",
      "116/116 [==============================] - 2s 19ms/step - loss: 38.5412 - val_loss: 61.9231\n",
      "Epoch 56/250\n",
      "116/116 [==============================] - 2s 19ms/step - loss: 36.7579 - val_loss: 60.1743\n",
      "Epoch 57/250\n",
      "116/116 [==============================] - 2s 18ms/step - loss: 38.3710 - val_loss: 54.6208\n",
      "Epoch 58/250\n",
      "116/116 [==============================] - 2s 18ms/step - loss: 37.4457 - val_loss: 53.1932\n",
      "Epoch 59/250\n",
      "116/116 [==============================] - 2s 18ms/step - loss: 38.7295 - val_loss: 49.7724\n",
      "Epoch 60/250\n",
      "116/116 [==============================] - 2s 18ms/step - loss: 34.6992 - val_loss: 47.2918\n",
      "Epoch 61/250\n",
      "116/116 [==============================] - 2s 18ms/step - loss: 35.5176 - val_loss: 44.5915\n",
      "Epoch 62/250\n",
      "116/116 [==============================] - 2s 18ms/step - loss: 35.6833 - val_loss: 41.7299\n",
      "Epoch 63/250\n",
      "116/116 [==============================] - 2s 20ms/step - loss: 33.2728 - val_loss: 40.3256\n",
      "Epoch 64/250\n",
      "116/116 [==============================] - 2s 19ms/step - loss: 34.5332 - val_loss: 37.6815\n",
      "Epoch 65/250\n",
      "116/116 [==============================] - 2s 19ms/step - loss: 31.9160 - val_loss: 35.8001\n",
      "Epoch 66/250\n",
      "116/116 [==============================] - 2s 19ms/step - loss: 36.7517 - val_loss: 33.3236\n",
      "Epoch 67/250\n",
      "116/116 [==============================] - 2s 18ms/step - loss: 32.5055 - val_loss: 32.5743\n",
      "Epoch 68/250\n",
      "116/116 [==============================] - 2s 18ms/step - loss: 31.6916 - val_loss: 29.5104\n",
      "Epoch 69/250\n",
      "116/116 [==============================] - 2s 18ms/step - loss: 31.8727 - val_loss: 30.2615\n",
      "Epoch 70/250\n",
      "116/116 [==============================] - 2s 18ms/step - loss: 30.1341 - val_loss: 27.6401\n",
      "Epoch 71/250\n",
      "116/116 [==============================] - 2s 18ms/step - loss: 31.0160 - val_loss: 26.5217\n",
      "Epoch 72/250\n",
      "116/116 [==============================] - 2s 18ms/step - loss: 30.5993 - val_loss: 25.5551\n",
      "Epoch 73/250\n",
      "116/116 [==============================] - 2s 17ms/step - loss: 29.6149 - val_loss: 23.5551\n",
      "Epoch 74/250\n",
      "116/116 [==============================] - 2s 18ms/step - loss: 30.6812 - val_loss: 22.3748\n",
      "Epoch 75/250\n",
      "116/116 [==============================] - 2s 18ms/step - loss: 29.5431 - val_loss: 21.6612\n",
      "Epoch 76/250\n",
      "116/116 [==============================] - 2s 18ms/step - loss: 30.5638 - val_loss: 22.5496\n",
      "Epoch 77/250\n",
      "116/116 [==============================] - 2s 21ms/step - loss: 28.3665 - val_loss: 20.5017\n",
      "Epoch 78/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116/116 [==============================] - 2s 21ms/step - loss: 28.9174 - val_loss: 19.8786\n",
      "Epoch 79/250\n",
      "116/116 [==============================] - 3s 23ms/step - loss: 28.6103 - val_loss: 19.7386\n",
      "Epoch 80/250\n",
      "116/116 [==============================] - 3s 26ms/step - loss: 28.1508 - val_loss: 18.5734\n",
      "Epoch 81/250\n",
      "116/116 [==============================] - 3s 22ms/step - loss: 28.9540 - val_loss: 15.9729\n",
      "Epoch 82/250\n",
      "116/116 [==============================] - 2s 21ms/step - loss: 29.4922 - val_loss: 15.6460\n",
      "Epoch 83/250\n",
      "116/116 [==============================] - 3s 23ms/step - loss: 28.4785 - val_loss: 16.2247\n",
      "Epoch 84/250\n",
      "116/116 [==============================] - 3s 22ms/step - loss: 27.7819 - val_loss: 14.7450\n",
      "Epoch 85/250\n",
      "116/116 [==============================] - 3s 22ms/step - loss: 28.9583 - val_loss: 15.8015\n",
      "Epoch 86/250\n",
      "116/116 [==============================] - 3s 22ms/step - loss: 26.4696 - val_loss: 14.2824\n",
      "Epoch 87/250\n",
      "116/116 [==============================] - 3s 22ms/step - loss: 28.2277 - val_loss: 15.2847\n",
      "Epoch 88/250\n",
      "116/116 [==============================] - 2s 21ms/step - loss: 26.9470 - val_loss: 15.2832\n",
      "Epoch 89/250\n",
      "116/116 [==============================] - 2s 21ms/step - loss: 29.5024 - val_loss: 13.9666\n",
      "Epoch 90/250\n",
      "116/116 [==============================] - 2s 21ms/step - loss: 26.9275 - val_loss: 14.1300\n",
      "Epoch 91/250\n",
      "116/116 [==============================] - 2s 21ms/step - loss: 27.4482 - val_loss: 13.3585\n",
      "Epoch 92/250\n",
      "116/116 [==============================] - 2s 21ms/step - loss: 26.2057 - val_loss: 16.3565\n",
      "Epoch 93/250\n",
      "116/116 [==============================] - 2s 21ms/step - loss: 27.6927 - val_loss: 15.5519\n",
      "Epoch 94/250\n",
      "116/116 [==============================] - 2s 21ms/step - loss: 25.8767 - val_loss: 14.4065\n",
      "Epoch 95/250\n",
      "116/116 [==============================] - 2s 21ms/step - loss: 26.2370 - val_loss: 14.3089\n",
      "Epoch 96/250\n",
      "116/116 [==============================] - 2s 21ms/step - loss: 27.9218 - val_loss: 14.5623\n",
      "Epoch 97/250\n",
      "116/116 [==============================] - 2s 21ms/step - loss: 26.4966 - val_loss: 13.5708\n",
      "Epoch 98/250\n",
      "116/116 [==============================] - 2s 21ms/step - loss: 25.9269 - val_loss: 14.0501\n",
      "Epoch 99/250\n",
      "116/116 [==============================] - 3s 22ms/step - loss: 26.2627 - val_loss: 13.3348\n",
      "Epoch 100/250\n",
      "116/116 [==============================] - 2s 21ms/step - loss: 25.5375 - val_loss: 14.0949\n",
      "Epoch 101/250\n",
      "116/116 [==============================] - 2s 21ms/step - loss: 25.7437 - val_loss: 14.1219\n",
      "Epoch 102/250\n",
      "116/116 [==============================] - 2s 21ms/step - loss: 25.4375 - val_loss: 13.0497\n",
      "Epoch 103/250\n",
      "116/116 [==============================] - 2s 21ms/step - loss: 25.5312 - val_loss: 13.6500\n",
      "Epoch 104/250\n",
      "116/116 [==============================] - 3s 22ms/step - loss: 24.9468 - val_loss: 12.4828\n",
      "Epoch 105/250\n",
      "116/116 [==============================] - 2s 21ms/step - loss: 28.0633 - val_loss: 13.2738\n",
      "Epoch 106/250\n",
      "116/116 [==============================] - 3s 22ms/step - loss: 24.7523 - val_loss: 12.7095\n",
      "Epoch 107/250\n",
      "116/116 [==============================] - 3s 23ms/step - loss: 25.3349 - val_loss: 13.5399\n",
      "Epoch 108/250\n",
      "116/116 [==============================] - 2s 21ms/step - loss: 25.6324 - val_loss: 14.1108\n",
      "Epoch 109/250\n",
      "116/116 [==============================] - 2s 21ms/step - loss: 24.4131 - val_loss: 13.0147\n",
      "Epoch 110/250\n",
      "116/116 [==============================] - 2s 21ms/step - loss: 25.7920 - val_loss: 10.8059\n",
      "Epoch 111/250\n",
      "116/116 [==============================] - 3s 22ms/step - loss: 25.1337 - val_loss: 12.5020\n",
      "Epoch 112/250\n",
      "116/116 [==============================] - 3s 23ms/step - loss: 24.3342 - val_loss: 12.2416\n",
      "Epoch 113/250\n",
      "116/116 [==============================] - 3s 24ms/step - loss: 25.7089 - val_loss: 14.3435\n",
      "Epoch 114/250\n",
      "116/116 [==============================] - 2s 21ms/step - loss: 25.5412 - val_loss: 12.4345\n",
      "Epoch 115/250\n",
      "116/116 [==============================] - 2s 21ms/step - loss: 24.4462 - val_loss: 14.2809\n",
      "Epoch 116/250\n",
      "116/116 [==============================] - 3s 23ms/step - loss: 25.2345 - val_loss: 10.3888\n",
      "Epoch 117/250\n",
      "116/116 [==============================] - 2s 21ms/step - loss: 25.0949 - val_loss: 11.2473\n",
      "Epoch 118/250\n",
      "116/116 [==============================] - 2s 21ms/step - loss: 25.7246 - val_loss: 12.2596\n",
      "Epoch 119/250\n",
      "116/116 [==============================] - 2s 21ms/step - loss: 23.5571 - val_loss: 12.1069\n",
      "Epoch 120/250\n",
      "116/116 [==============================] - 3s 22ms/step - loss: 24.0727 - val_loss: 11.3231\n",
      "Epoch 121/250\n",
      "116/116 [==============================] - 3s 22ms/step - loss: 23.8983 - val_loss: 11.9846\n",
      "Epoch 122/250\n",
      "116/116 [==============================] - 2s 21ms/step - loss: 23.7358 - val_loss: 11.9275\n",
      "Epoch 123/250\n",
      "116/116 [==============================] - 3s 22ms/step - loss: 25.5141 - val_loss: 10.4235\n",
      "Epoch 124/250\n",
      "116/116 [==============================] - 3s 22ms/step - loss: 23.0914 - val_loss: 12.7935\n",
      "Epoch 125/250\n",
      "116/116 [==============================] - 2s 21ms/step - loss: 23.5913 - val_loss: 10.1268\n",
      "Epoch 126/250\n",
      "116/116 [==============================] - 3s 22ms/step - loss: 24.3525 - val_loss: 11.7406\n",
      "Epoch 127/250\n",
      "116/116 [==============================] - 3s 22ms/step - loss: 23.8369 - val_loss: 14.4714\n",
      "Epoch 128/250\n",
      "116/116 [==============================] - 2s 21ms/step - loss: 23.7245 - val_loss: 11.2949\n",
      "Epoch 129/250\n",
      "116/116 [==============================] - 3s 22ms/step - loss: 23.5656 - val_loss: 12.4777\n",
      "Epoch 130/250\n",
      "116/116 [==============================] - 2s 21ms/step - loss: 25.0772 - val_loss: 12.0278\n",
      "Epoch 131/250\n",
      "116/116 [==============================] - 3s 22ms/step - loss: 23.5055 - val_loss: 11.5743\n",
      "Epoch 132/250\n",
      "116/116 [==============================] - 3s 22ms/step - loss: 23.2810 - val_loss: 13.2971\n",
      "Epoch 133/250\n",
      "116/116 [==============================] - 3s 22ms/step - loss: 24.8449 - val_loss: 15.3614\n",
      "Epoch 134/250\n",
      "116/116 [==============================] - 2s 21ms/step - loss: 23.2502 - val_loss: 12.4962\n",
      "Epoch 135/250\n",
      "116/116 [==============================] - 3s 22ms/step - loss: 26.4245 - val_loss: 15.1263\n",
      "Epoch 136/250\n",
      "116/116 [==============================] - 3s 22ms/step - loss: 21.7021 - val_loss: 12.6025\n",
      "Epoch 137/250\n",
      "116/116 [==============================] - 2s 21ms/step - loss: 21.8305 - val_loss: 12.7312\n",
      "Epoch 138/250\n",
      "116/116 [==============================] - 2s 21ms/step - loss: 22.0021 - val_loss: 12.0906\n",
      "Epoch 139/250\n",
      "116/116 [==============================] - 2s 21ms/step - loss: 22.3524 - val_loss: 12.3863\n",
      "Epoch 140/250\n",
      "116/116 [==============================] - 2s 21ms/step - loss: 22.3368 - val_loss: 12.9103\n",
      "Epoch 141/250\n",
      "116/116 [==============================] - 2s 21ms/step - loss: 21.0767 - val_loss: 9.0505\n",
      "Epoch 142/250\n",
      "116/116 [==============================] - 2s 21ms/step - loss: 21.7671 - val_loss: 11.4464\n",
      "Epoch 143/250\n",
      "116/116 [==============================] - 3s 22ms/step - loss: 21.9193 - val_loss: 12.1328\n",
      "Epoch 144/250\n",
      "116/116 [==============================] - 3s 22ms/step - loss: 21.6074 - val_loss: 10.6889\n",
      "Epoch 145/250\n",
      "116/116 [==============================] - 2s 22ms/step - loss: 21.4895 - val_loss: 11.3332\n",
      "Epoch 146/250\n",
      "116/116 [==============================] - 3s 22ms/step - loss: 20.5579 - val_loss: 10.7494\n",
      "Epoch 147/250\n",
      "116/116 [==============================] - 3s 23ms/step - loss: 19.6280 - val_loss: 9.5907\n",
      "Epoch 148/250\n",
      "116/116 [==============================] - 3s 22ms/step - loss: 21.9449 - val_loss: 9.6637\n",
      "Epoch 149/250\n",
      "116/116 [==============================] - 2s 21ms/step - loss: 20.3693 - val_loss: 10.8850\n",
      "Epoch 150/250\n",
      "116/116 [==============================] - 2s 21ms/step - loss: 20.8919 - val_loss: 10.3173\n",
      "Epoch 151/250\n",
      "116/116 [==============================] - 2s 21ms/step - loss: 20.2367 - val_loss: 10.9254\n",
      "Epoch 152/250\n",
      "116/116 [==============================] - 3s 23ms/step - loss: 20.3930 - val_loss: 10.3326\n",
      "Epoch 153/250\n",
      "116/116 [==============================] - 3s 23ms/step - loss: 21.2345 - val_loss: 9.2504\n",
      "Epoch 154/250\n",
      "116/116 [==============================] - 3s 23ms/step - loss: 21.4772 - val_loss: 7.5273\n",
      "Epoch 155/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116/116 [==============================] - 3s 23ms/step - loss: 19.9747 - val_loss: 8.1267\n",
      "Epoch 156/250\n",
      "116/116 [==============================] - 3s 22ms/step - loss: 20.0814 - val_loss: 11.5955\n",
      "Epoch 157/250\n",
      "116/116 [==============================] - 2s 21ms/step - loss: 20.0321 - val_loss: 9.3236\n",
      "Epoch 158/250\n",
      "116/116 [==============================] - 2s 20ms/step - loss: 19.8631 - val_loss: 8.9605\n",
      "Epoch 159/250\n",
      "116/116 [==============================] - 2s 21ms/step - loss: 20.0353 - val_loss: 11.1108\n",
      "Epoch 160/250\n",
      "116/116 [==============================] - 2s 21ms/step - loss: 19.3706 - val_loss: 7.9677\n",
      "Epoch 161/250\n",
      "116/116 [==============================] - 2s 19ms/step - loss: 19.0854 - val_loss: 8.1967\n",
      "Epoch 162/250\n",
      "116/116 [==============================] - 2s 20ms/step - loss: 19.3230 - val_loss: 9.9161\n",
      "Epoch 163/250\n",
      "116/116 [==============================] - 2s 19ms/step - loss: 20.0208 - val_loss: 8.6862\n",
      "Epoch 164/250\n",
      "116/116 [==============================] - 2s 20ms/step - loss: 19.0840 - val_loss: 7.1979\n",
      "Epoch 165/250\n",
      "116/116 [==============================] - 2s 20ms/step - loss: 18.8283 - val_loss: 6.7130\n",
      "Epoch 166/250\n",
      "116/116 [==============================] - 2s 20ms/step - loss: 19.7158 - val_loss: 8.8064\n",
      "Epoch 167/250\n",
      "116/116 [==============================] - 2s 20ms/step - loss: 20.3228 - val_loss: 7.2066\n",
      "Epoch 168/250\n",
      "116/116 [==============================] - 2s 20ms/step - loss: 18.9198 - val_loss: 7.7122\n",
      "Epoch 169/250\n",
      "116/116 [==============================] - 2s 20ms/step - loss: 18.7477 - val_loss: 9.8260\n",
      "Epoch 170/250\n",
      "116/116 [==============================] - 2s 20ms/step - loss: 18.6587 - val_loss: 7.3241\n",
      "Epoch 171/250\n",
      "116/116 [==============================] - 2s 20ms/step - loss: 19.0824 - val_loss: 8.4442\n",
      "Epoch 172/250\n",
      "116/116 [==============================] - 2s 20ms/step - loss: 19.1286 - val_loss: 8.3789\n",
      "Epoch 173/250\n",
      "116/116 [==============================] - 2s 20ms/step - loss: 18.3001 - val_loss: 8.9158\n",
      "Epoch 174/250\n",
      "116/116 [==============================] - 2s 21ms/step - loss: 18.3355 - val_loss: 8.7411\n",
      "Epoch 175/250\n",
      "116/116 [==============================] - 2s 20ms/step - loss: 18.5026 - val_loss: 8.2832\n",
      "Epoch 176/250\n",
      "116/116 [==============================] - 2s 20ms/step - loss: 19.4039 - val_loss: 10.8838\n",
      "Epoch 177/250\n",
      "116/116 [==============================] - 2s 20ms/step - loss: 19.1760 - val_loss: 6.9659\n",
      "Epoch 178/250\n",
      "116/116 [==============================] - 2s 21ms/step - loss: 18.0885 - val_loss: 7.5839\n",
      "Epoch 179/250\n",
      "116/116 [==============================] - 2s 21ms/step - loss: 17.8861 - val_loss: 8.6011\n",
      "Epoch 180/250\n",
      "116/116 [==============================] - 2s 20ms/step - loss: 18.6451 - val_loss: 7.9800\n",
      "Epoch 181/250\n",
      "116/116 [==============================] - 2s 21ms/step - loss: 17.5725 - val_loss: 7.2602\n",
      "Epoch 182/250\n",
      "116/116 [==============================] - 2s 21ms/step - loss: 18.3127 - val_loss: 8.2404\n",
      "Epoch 183/250\n",
      "116/116 [==============================] - 2s 20ms/step - loss: 18.3821 - val_loss: 7.2019\n",
      "Epoch 184/250\n",
      "116/116 [==============================] - 2s 21ms/step - loss: 18.0713 - val_loss: 6.8840\n",
      "Epoch 185/250\n",
      "116/116 [==============================] - 2s 21ms/step - loss: 19.0307 - val_loss: 8.5426\n",
      "Epoch 186/250\n",
      "116/116 [==============================] - 2s 21ms/step - loss: 19.2347 - val_loss: 7.5243\n",
      "Epoch 187/250\n",
      "116/116 [==============================] - 2s 20ms/step - loss: 18.2028 - val_loss: 7.0332\n",
      "Epoch 188/250\n",
      "116/116 [==============================] - 2s 21ms/step - loss: 17.1420 - val_loss: 6.4137\n",
      "Epoch 189/250\n",
      "116/116 [==============================] - 2s 21ms/step - loss: 17.9497 - val_loss: 6.9593\n",
      "Epoch 190/250\n",
      "116/116 [==============================] - 2s 21ms/step - loss: 17.9067 - val_loss: 7.1997\n",
      "Epoch 191/250\n",
      "116/116 [==============================] - 2s 21ms/step - loss: 17.3474 - val_loss: 7.4959\n",
      "Epoch 192/250\n",
      "116/116 [==============================] - 2s 21ms/step - loss: 17.2242 - val_loss: 6.4975\n",
      "Epoch 193/250\n",
      "116/116 [==============================] - 2s 21ms/step - loss: 17.2691 - val_loss: 7.6489\n",
      "Epoch 194/250\n",
      "116/116 [==============================] - 2s 20ms/step - loss: 17.0145 - val_loss: 6.2763\n",
      "Epoch 195/250\n",
      "116/116 [==============================] - 2s 20ms/step - loss: 17.5289 - val_loss: 5.8102\n",
      "Epoch 196/250\n",
      "116/116 [==============================] - 2s 21ms/step - loss: 18.3961 - val_loss: 6.2510\n",
      "Epoch 197/250\n",
      "116/116 [==============================] - 2s 21ms/step - loss: 17.1992 - val_loss: 6.2932\n",
      "Epoch 198/250\n",
      "116/116 [==============================] - 2s 21ms/step - loss: 16.7815 - val_loss: 6.4985\n",
      "Epoch 199/250\n",
      "116/116 [==============================] - 2s 21ms/step - loss: 16.9282 - val_loss: 8.3943\n",
      "Epoch 200/250\n",
      "116/116 [==============================] - 3s 23ms/step - loss: 18.1920 - val_loss: 5.7841\n",
      "Epoch 201/250\n",
      "116/116 [==============================] - 3s 24ms/step - loss: 16.9293 - val_loss: 7.1975\n",
      "Epoch 202/250\n",
      "116/116 [==============================] - 2s 21ms/step - loss: 16.8144 - val_loss: 6.8585\n",
      "Epoch 203/250\n",
      "116/116 [==============================] - 3s 22ms/step - loss: 18.4118 - val_loss: 6.8311\n",
      "Epoch 204/250\n",
      "116/116 [==============================] - 3s 22ms/step - loss: 17.7133 - val_loss: 7.8639\n",
      "Epoch 205/250\n",
      "116/116 [==============================] - 3s 22ms/step - loss: 16.8219 - val_loss: 7.0532\n",
      "Epoch 206/250\n",
      "116/116 [==============================] - 3s 22ms/step - loss: 18.4296 - val_loss: 8.4882\n",
      "Epoch 207/250\n",
      "116/116 [==============================] - 2s 21ms/step - loss: 16.6340 - val_loss: 7.0458\n",
      "Epoch 208/250\n",
      "116/116 [==============================] - 2s 21ms/step - loss: 16.2180 - val_loss: 7.7286\n",
      "Epoch 209/250\n",
      "116/116 [==============================] - 2s 21ms/step - loss: 15.8002 - val_loss: 6.8740\n",
      "Epoch 210/250\n",
      "116/116 [==============================] - 2s 20ms/step - loss: 17.9828 - val_loss: 6.8097\n",
      "Epoch 211/250\n",
      "116/116 [==============================] - 2s 20ms/step - loss: 17.0176 - val_loss: 8.1862\n",
      "Epoch 212/250\n",
      "116/116 [==============================] - 2s 21ms/step - loss: 17.6384 - val_loss: 5.8649\n",
      "Epoch 213/250\n",
      "116/116 [==============================] - 2s 21ms/step - loss: 17.8232 - val_loss: 7.4661\n",
      "Epoch 214/250\n",
      "116/116 [==============================] - 2s 21ms/step - loss: 16.8683 - val_loss: 7.0144\n",
      "Epoch 215/250\n",
      "116/116 [==============================] - 3s 22ms/step - loss: 17.8103 - val_loss: 9.0810\n",
      "Epoch 216/250\n",
      "116/116 [==============================] - 2s 21ms/step - loss: 15.8376 - val_loss: 6.6622\n",
      "Epoch 217/250\n",
      "116/116 [==============================] - 3s 22ms/step - loss: 16.1630 - val_loss: 6.2261\n",
      "Epoch 218/250\n",
      "116/116 [==============================] - 3s 23ms/step - loss: 16.6838 - val_loss: 7.6061\n",
      "Epoch 219/250\n",
      "116/116 [==============================] - 3s 22ms/step - loss: 16.7707 - val_loss: 7.1889\n",
      "Epoch 220/250\n",
      "116/116 [==============================] - 3s 22ms/step - loss: 15.9630 - val_loss: 9.1737\n",
      "Epoch 221/250\n",
      "116/116 [==============================] - 3s 22ms/step - loss: 15.8058 - val_loss: 8.8027\n",
      "Epoch 222/250\n",
      "116/116 [==============================] - 2s 21ms/step - loss: 15.9902 - val_loss: 7.6326\n",
      "Epoch 223/250\n",
      "116/116 [==============================] - 3s 23ms/step - loss: 16.2498 - val_loss: 7.5975\n",
      "Epoch 224/250\n",
      "116/116 [==============================] - 2s 21ms/step - loss: 16.5412 - val_loss: 7.4514\n",
      "Epoch 225/250\n",
      "116/116 [==============================] - 2s 21ms/step - loss: 15.4290 - val_loss: 9.1046\n",
      "Epoch 226/250\n",
      "116/116 [==============================] - 2s 21ms/step - loss: 17.6712 - val_loss: 8.9048\n",
      "Epoch 227/250\n",
      "116/116 [==============================] - 3s 25ms/step - loss: 15.9854 - val_loss: 6.7180\n",
      "Epoch 228/250\n",
      "116/116 [==============================] - 2s 21ms/step - loss: 15.8743 - val_loss: 8.2975\n",
      "Epoch 229/250\n",
      "116/116 [==============================] - 2s 21ms/step - loss: 15.9229 - val_loss: 9.5276\n",
      "Epoch 230/250\n",
      "116/116 [==============================] - 3s 22ms/step - loss: 16.2298 - val_loss: 8.5970\n",
      "Epoch 231/250\n",
      "116/116 [==============================] - 2s 21ms/step - loss: 14.9164 - val_loss: 10.3182\n",
      "Epoch 232/250\n",
      "116/116 [==============================] - 2s 21ms/step - loss: 15.4362 - val_loss: 8.8456\n",
      "Epoch 233/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116/116 [==============================] - 2s 21ms/step - loss: 14.9981 - val_loss: 9.0963\n",
      "Epoch 234/250\n",
      "116/116 [==============================] - 2s 21ms/step - loss: 16.2450 - val_loss: 7.9576\n",
      "Epoch 235/250\n",
      "116/116 [==============================] - 2s 21ms/step - loss: 14.8354 - val_loss: 10.8122\n",
      "Epoch 236/250\n",
      "116/116 [==============================] - 2s 20ms/step - loss: 15.5369 - val_loss: 9.5537\n",
      "Epoch 237/250\n",
      "116/116 [==============================] - 2s 21ms/step - loss: 15.3033 - val_loss: 9.7827\n",
      "Epoch 238/250\n",
      "116/116 [==============================] - 2s 21ms/step - loss: 14.8212 - val_loss: 10.1702\n",
      "Epoch 239/250\n",
      "116/116 [==============================] - 2s 21ms/step - loss: 14.9702 - val_loss: 10.3396\n",
      "Epoch 240/250\n",
      "116/116 [==============================] - 2s 19ms/step - loss: 15.2004 - val_loss: 15.0393\n",
      "Epoch 241/250\n",
      "116/116 [==============================] - 2s 20ms/step - loss: 15.9646 - val_loss: 9.5420\n",
      "Epoch 242/250\n",
      "116/116 [==============================] - 2s 20ms/step - loss: 15.8537 - val_loss: 10.2541\n",
      "Epoch 243/250\n",
      "116/116 [==============================] - 2s 20ms/step - loss: 14.5236 - val_loss: 11.0372\n",
      "Epoch 244/250\n",
      "116/116 [==============================] - 2s 21ms/step - loss: 18.5537 - val_loss: 10.7834\n",
      "Epoch 245/250\n",
      "116/116 [==============================] - 2s 21ms/step - loss: 15.5723 - val_loss: 10.5401\n",
      "Epoch 246/250\n",
      "116/116 [==============================] - 2s 20ms/step - loss: 14.7986 - val_loss: 10.7063\n",
      "Epoch 247/250\n",
      "116/116 [==============================] - 2s 20ms/step - loss: 14.6939 - val_loss: 9.6853\n",
      "Epoch 248/250\n",
      "116/116 [==============================] - 2s 21ms/step - loss: 14.5955 - val_loss: 12.1576\n",
      "Epoch 249/250\n",
      "116/116 [==============================] - 2s 20ms/step - loss: 14.2076 - val_loss: 10.4922\n",
      "Epoch 250/250\n",
      "116/116 [==============================] - 2s 20ms/step - loss: 14.6501 - val_loss: 10.1065\n"
     ]
    }
   ],
   "source": [
    "history = chili_model.fit(train, epochs=EPOCHS, steps_per_epoch=len(x_train), \n",
    "                validation_data=val, validation_steps=len(x_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_model_result(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "evaluate the trained model with test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 28ms/sample - loss: 57.4931\n"
     ]
    }
   ],
   "source": [
    "results = chili_model.evaluate(x_test, y_test, batch_size=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "save the trained model weights into a h5 file so it can be loaded later (no need to re-train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "chili_model.save_weights(\"chili.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try to predict Chili (bird's eye) price using Chili (red) forecasting model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "155"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_chili_bird = drop_unused_row_column(df, \"bird\")\n",
    "#Chili (birdâ€™s eye) - Retail\n",
    "data_bird = df_chili_bird[\"mp_price\"].values / 1000\n",
    "len(data_bird)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y, _, _ = split_data(data, len(data_bird), HISTORY_SIZE)\n",
    "\n",
    "# test_bird = tf.data.Dataset.from_tensor_slices((x, y))\n",
    "# test_bird = test_bird.cache().shuffle(BUFFER_SIZE).batch(BATCH_SIZE).repeat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "145/145 [==============================] - 0s 1ms/sample - loss: 18.0606\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "18.060553674040168"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chili_model.evaluate(x, y, batch_size=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
